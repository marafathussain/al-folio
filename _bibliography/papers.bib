---
---

@string{aps = {American Physical Society,}}

@article{hussain2023enhancing,
abbr={bioRxiv},
bibtex_show={true},
selected={false},
title = {Enhancing Neurocognitive Outcome Prediction in Congenital Heart Disease Patients: The Role of Brain Age Biomarkers and Beyond},
journal = {bioRxiv},
pdf={CHD_neuro_2023.pdf},
author={Hussain, Mohammad Arafat and Li, Grace and Grant, Ellen and Ou, Yangming},
abstract = {This paper aimed to investigate the predictive power of combining demographic, socioeconomic, and genetic factors with a brain MRI-based quantified measure of accelerated brain aging (referred to as deltaAGE) for neurocognitive outcomes in adolescents and young adults with Congenital Heart Disease (CHD). Our hypothesis posited that including the brain age biomarker (deltaAGE) would enhance neurocognitive outcome predictions compared to models excluding it. We conducted comprehensive analyses, including leave-one-subject-out and leave-one-group-out cross-validation techniques. Our results demonstrated that the inclusion of deltaAGE consistently improved prediction performance when considering the Pearson correlation coefficient, a preferable metric for this study. Notably, the deltaAGE-augmented models consistently outperformed those without deltaAGE across all cross-validation setups, and these correlations were statistically significant (p-value < 0.05). Therefore, our hypothesis that incorporating the brain-age biomarker alongside demographic, socioeconomic, and genetic factors enhances neurocognitive outcome predictions in adolescents and young adults with CHD is supported by the findings.}
}

@article{MARHAMATI2023102371,
abbr={Displays},
bibtex_show={true},
selected={false},
title = {LAIU-Net: A learning-to-augment incorporated robust U-Net for depressed humans’ tongue segmentation},
journal = {Displays},
pages = {102371},
year = {2023},
issn = {0141-9382},
pdf={displays2023.pdf},
doi = {https://doi.org/10.1016/j.displa.2023.102371},
html = {https://www.sciencedirect.com/science/article/pii/S0141938223000045},
author = {Mahmoud Marhamati and Ali Asghar Latifi Zadeh and Masoud Mojdehi Fard and Mohammad Arafat Hussain and Khalegh Jafarnezhad and Ahad Jafarnezhad and Mehdi Bakhtoor and Mohammad Momeny},
keywords = {Tongue segmentation, learning-to-augment strategy, data augmentation, deep learning, U-Net},
code={https://github.com/mohamadmomeny/Learning-to-augment-strategy},
abstract = {Computer-aided tongue diagnosis system requires segmentation of the tongue body. The frequent movement of the tongue due to its natural flexibility often causes shape variability in photographs across subjects, which makes segmenting the tongue challenging from non-tongue elements, such as the lips, teeth, and other objects in the background of the tongue. The flexibility of the tongue causes a further challenge in maintaining a similar shape and style when taking photos of many healthy subjects and patients. To address these challenges, we have built a tongue dataset, where the tongue of each subject has been scanned thrice with an interval of less than a second. We have collected 333 tongue images from 111 depressed humans, who have been diagnosed with depression by a psychiatrist. In addition, in this paper, we propose a learning-to-augment incorporated U-Net (LAIU-Net) for the segmentation of the depressed human tongue in photographic images. The best policies for data augmentation were automatically chosen with the proposed LAIU-Net. For this purpose, we corrupted photographic tongue images with the Gaussian, speckle, and Poisson noise. The proposed approach addresses the overfitting problem as well as increases the generalizability of a deep network. We have compared the performance of the proposed LAIU-Net with that of other state-of-the-art U-Net configurations. Our LAIU-Net approach achieved a mean boundary F1 score of 93.1%.}
}

@article{morshed2023ultrasound,
  abbr={Preprints},
  bibtex_show={true},
  selected={true},
  pdf={https://www.preprints.org/manuscript/202303.0296/v3/download},
  doi = {https://doi.org/10.20944/preprints202303.0296.v3},
  html = {https://www.preprints.org/manuscript/202303.0296/v3},
  journal={Preprints},
  title={Ultrasound-Based AI for COVID-19 Detection: A Comprehensive Review of Public and Private Lung Ultrasound Datasets and Studies},
  author={Morshed, Abrar and Al Shihab, Abdulla and Jahin, Md Abrar and Al Nahian, Md Jaber and Sarker, Md Murad Hossain and Wadud, Md Sharjis Ibne and Uddin, Mohammad Istiaq and Siraji, Muntequa Imtiaz and Anjum, Nafisa and Shristy, Sumiya Rajjab and others},
  year={2023},
  abstract={The COVID-19 pandemic has affected millions of people globally, with respiratory organs being strongly affected in individuals with comorbidities. Medical imaging-based diagnosis and prognosis have become increasingly popular in clinical settings to detect COVID-19 lung infections. Among various medical imaging modalities, ultrasound stands out as low-cost, mobile, and radiation-safe imaging technology. In this comprehensive review, we focus on ultrasound-based AI studies for COVID-19 detection that use public or private lung ultrasound datasets. We surveyed articles that used publicly available lung ultrasound datasets for COVID-19 and reviewed publicly available datasets and organize ultrasound-based AI studies per dataset. We analyzed and tabulated studies in several dimensions, such as data preprocessing, AI models, cross-validation, and evaluation criteria. In total, we reviewed 42 articles, where 28 articles used public datasets, and the rest used private data. Our findings suggest that ultrasound-based AI studies for the detection of COVID-19 have great potential for clinical use, especially for children and pregnant women. Our review also provides a useful summary for future researchers and clinicians who may be interested in the field.},
  publisher={Preprints}
}

@article{hussain2023can,
  abbr={bioRxiv},
  bibtex_show={true},
  selected={true},
  pdf={https://www.biorxiv.org/content/10.1101/2023.02.24.529924v1.full.pdf},
  doi = {https://doi.org/10.1101/2023.02.24.529924},
  html = {https://www.biorxiv.org/content/10.1101/2023.02.24.529924v1},
  title={Can deep learning predict human intelligence from structural brain MRI?},
  author={Hussain, Mohammad Arafat and LaMay, Danielle and Grant, Ellen and Ou, Yangming},
  journal={bioRxiv},
  pages={2023--02},
  year={2023},
  code={https://github.com/i3-research/MRI-infer-neurocognition},
  abstract={Can brain structure predict human intelligence? T1-weighted structural brain magnetic resonance images (sMRI) have been correlated with intelligence. Nevertheless, population-level association does not fully account for individual variability in intelligence. To address this, individual prediction studies emerge recently. However, they are mostly on predicting fluid intelligence (the ability to solve new problems). Studies are lacking to predict crystallized intelligence (the ability to accumulate knowledge) or general intelligence (fluid and crystallized intelligence combined). This study tests whether deep learning of sMRI can predict an individual subject’s verbal, comprehensive, and full-scale intelligence quotients (VIQ, PIQ, FSIQ), which reflect both fluid and crystallized intelligence. We performed a comprehensive set of 432 experiments, using different input images, six deep learning models, and two outcome settings, on 850 autistic and healthy subjects 6-64 years of age. Results show promise with statistical significance, and also open up questions inviting further future studies.},
  publisher={Cold Spring Harbor Laboratory}
}

@article{hussain2023influence,
  abbr={bioRxiv},
  selected={true},
  bibtex_show={true},
  pdf={https://www.biorxiv.org/content/biorxiv/early/2023/02/27/2023.02.24.529930.full.pdf},
  doi = {https://doi.org/10.1101/2023.02.24.529930},
  html = {https://www.biorxiv.org/content/10.1101/2023.02.24.529930v1.abstract},
  title={Influence of Demographic, Socio-economic, and Brain Structural Factors on Adolescent Neurocognition: A Correlation Analysis in the ABCD Initiative},
  author={Hussain, Mohammad Arafat and Li, Grace and Grant, Ellen and Ou, Yangming},
  journal={bioRxiv},
  pages={2023--02},
  year={2023},
  abstract={The Adolescent Brain Cognitive Development (ABCD) initiative is a longitudinal study aimed at characterizing brain development from childhood through adolescence and identifying key biological and environmental factors that influence this development. The study measures neurocognitive abilities across a multidimensional array of functions, with a focus on the critical period of adolescence during which physical and socio-emotional changes occur and the structure of the cortical and white matter changes. In this study, we perform a correlation analysis to examine the linear relation of adolescent neurocognition functions with the demographic, socio-economic, and magnetic resonance imaging-based brain structural factors. The overall goal is to obtain a comprehensive understanding of how natural and nurtural factors influence adolescent neurocognition. Our results on > 10,000 adolescents show many positive and negative statistical significance interrelations of different neurocognitive functions with the demographic, socioeconomic, and brain structural factors, and also open up questions inviting further future studies.},
  publisher={Cold Spring Harbor Laboratory}
}

@article{hussain2023inferring,
  abbr={Preprints},
  selected={true},
  bibtex_show={true},
  pdf={https://www.preprints.org/manuscript/202302.0452/v1/download},
  doi = {https://doi.org/10.20944/preprints202302.0452.v1},
  html = {https://www.preprints.org/manuscript/202302.0452/v1},
  journal={Preprints},
  title={Inferring Neurocognition and Intelligence using Brain MRI},
  author={Hussain, Mohammad Arafat and Grant, Ellen and Ou, Yangming},
  year={2023},
  abstract={Brain magnetic resonance imaging (MRI) offers a unique lens to study neuroanatomic support of human neurocognition and intelligence. A core mystery is the MRI explanation of individual differences in neurocognition and intelligence. The past four decades have seen great advancement in studying this century-long mystery, but the sample size and population-level studies limit the explanation at the individual level. The recent rise of big data and artificial intelligence offers novel opportunities. Yet, data sources, harmonization, study design, and interpretation need to be carefully considered. This review aims to summarize past work, discuss rising opportunities and challenges, and facilitate further investigations on machine intelligence inferring human intelligence.},
  publisher={Preprints}
}

@article{HUSSAIN2022102127,
abbr={CMIG},
selected={true},
bibtex_show={true},
title = {Active deep learning from a noisy teacher for semi-supervised 3D image segmentation: Application to COVID-19 pneumonia infection in CT},
journal = {Computerized Medical Imaging and Graphics},
pages = {102127},
year = {2022},
issn = {0895-6111},
pdf={cmig2022.pdf},
doi = {https://doi.org/10.1016/j.compmedimag.2022.102127},
html = {https://www.sciencedirect.com/science/article/pii/S0895611122000970},
author = {Mohammad Arafat Hussain and Zahra Mirikharaji and Mohammad Momeny and Mahmoud Marhamati and Ali Asghar Neshat and Rafeef Garbi and Ghassan Hamarneh},
keywords = {Deep learning, Semi-supervised learning, Active learning, Segmentation, Noisy teacher, COVID-19, Pneumonia},
code={https://github.com/marafathussain/ALNT},
abstract = {Supervised deep learning has become a standard approach to solving medical image segmentation tasks. However, serious difficulties in attaining pixel-level annotations for sufficiently large volumetric datasets in real-life applications have highlighted the critical need for alternative approaches, such as semi-supervised learning, where model training can leverage small expert-annotated datasets to enable learning from much larger datasets without laborious annotation. Most of the semi-supervised approaches combine expert annotations and machine-generated annotations with equal weights within deep model training, despite the latter annotations being relatively unreliable and likely to affect model optimization negatively. To overcome this, we propose an active learning approach that uses an example re-weighting strategy, where machine-annotated samples are weighted (i) based on the similarity of their gradient directions of descent to those of expert-annotated data, and (ii) based on the gradient magnitude of the last layer of the deep model. Specifically, we present an active learning strategy with a query function that enables the selection of reliable and more informative samples from machine-annotated batch data generated by a noisy teacher. When validated on clinical COVID-19 CT benchmark data, our method improved the performance of pneumonia infection segmentation compared to the state of the art.},
publisher={Elsevier}
}

@article{AKBARIMAJD2022101763,
abbr={JCS},
selected={false},
bibtex_show={true},
title = {Learning-to-augment incorporated noise-robust deep CNN for detection of COVID-19 in noisy X-ray images},
journal = {Journal of Computational Science},
volume = {63},
pages = {101763},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2022.101763},
html = {https://www.sciencedirect.com/science/article/pii/S1877750322001466},
pdf={jsc2022.pdf},
author = {Adel Akbarimajd and Nicolas Hoertel and Mohammad Arafat Hussain and Ali Asghar Neshat and Mahmoud Marhamati and Mahdi Bakhtoor and Mohammad Momeny},
keywords = {Noise, Adaptive resize, Adaptive convolution, Data augmentation, COVID-19 classification},
code={https://github.com/mohamadmomeny/Learning-to-augment-strategy},
abstract = {Deep convolutional neural networks (CNNs) are used for the detection of COVID-19 in X-ray images. The detection performance of deep CNNs may be reduced by noisy X-ray images. To improve the robustness of a deep CNN against impulse noise, we propose a novel CNN approach using adaptive convolution, with the aim to ameliorate COVID-19 detection in noisy X-ray images without requiring any preprocessing for noise removal. This approach includes an impulse noise-map layer, an adaptive resizing layer, and an adaptive convolution layer to the conventional CNN framework. We also used a learning-to-augment strategy using noisy X-ray images to improve the generalization of a deep CNN. We have collected a dataset of 2093 chest X-ray images including COVID-19 (452 images), non-COVID pneumonia (621 images), and healthy ones (1020 images). The architecture of pre-trained networks such as SqueezeNet, GoogleNet, MobileNetv2, ResNet18, ResNet50, ShuffleNet, and EfficientNetb0 has been modified to increase their robustness to impulse noise. Validation on the noisy X-ray images using the proposed noise-robust layers and learning-to-augment strategy-incorporated ResNet50 showed 2% better classification accuracy compared with state-of-the-art method.}
}

@inproceedings{lankalapalli2022accelerated,
  abbr={ASNR},
  selected={true},
  bibtex_show={true},
  title={Accelerated Brain Aging in Congenital Heart Disease and Relation to Neurodevelopmental Outcome},
  author={Lankalapalli, Ruhika and He, Sheng and Ko, James and Hussain, Mohammad Arafat and Im, Kiho and Chung, Ai Wern and Johnston, Patric and Newburger, Jane and Morton, Sarah and Grant, Ellen and Ou, Yangming},
  booktitle={60th Annual Meeting of the American Society of Neuroradiology},
  year={2022},
  pdf={ruhika_asnr_2022.pdf},
  organization={ASNR}
}

@inproceedings{hussain2022machine,
  abbr={Nature Conf.},
  selected={true},
  bibtex_show={true},
  title={Machine Intelligence to Predict Human Intelligence},
  author={Hussain, Mohammad Arafat and LaMay, Danielle and Grant, Ellen and Ou, Yangming},
  booktitle={AI, neuroscience and hardware: From neural to artificial systems and back again},
  year={2022},
  pdf={mah_nat_2022.pdf},
  poster={Nature_AI_Poster.pdf},
  organization={Nature Conferences}
}

@article{momeny2021learning,
  abbr={CIBM},
  selected={true},
  bibtex_show={true},
  title={Learning-to-Augment Strategy using Noisy and Denoised Data: Improving Generalizability of Deep CNN for the Detection of COVID-19 in X-ray Images},
  author={Momeny, Mohammad and Neshat, Ali Asghar and Hussain, Mohammad Arafat and Kia, Solmaz and Marhamati, Mahmoud and Jahanbakhshi, Ahmad and Hamarneh, Ghassan},
  journal={Computers in Biology and Medicine},
  html={https://www.sciencedirect.com/science/article/abs/pii/S0010482521004984},
  year={2021},
  pdf={cibm2021.pdf},
  abstract={Chest X-ray images are used in deep convolutional neural networks for the detection of COVID-19, the greatest human challenge of the 21st century. Robustness to noise and improvement of generalization are the major challenges in designing these networks. In this paper, we introduce a strategy for data augmentation using the determination of the type and value of noise density to improve the robustness and generalization of deep CNNs for COVID-19 detection. Firstly, we present a learning-to-augment approach that generates new noisy variants of the original image data with optimized noise density. We apply a Bayesian optimization technique to control and choose the optimal noise type and its parameters. Secondly, we propose a novel data augmentation strategy, based on denoised X-ray images, that uses the distance between denoised and original pixels to generate new data. We develop an autoencoder model to create new data using denoised images corrupted by the Gaussian and impulse noise. A database of chest X-ray images, containing COVID-19 positive images, normal images, and other non-COVID pneumonia images, is used to fine-tune the pre-trained networks (AlexNet, ShuffleNet, ResNet18, and GoogleNet). The proposed method has the better performance in comparison with the data augmentation approaches in terms of sensitivity (by 0.808), specificity (by 0.915), and F-Measure (by 0.737).},
  code={https://github.com/mohamadmomeny/Learning-to-augment-strategy},
  publisher={Elsevier}
}

@article{hussain2021learnable,
  abbr={CMIG},
  selected={true},
  bibtex_show={true},
  title={Learnable Image Histograms-based Deep Radiomics for Renal Cell Carcinoma Grading and Staging},
  author={Hussain, Mohammad Arafat and Hamarneh, Ghassan and Garbi, Rafeef},
  journal={Computerized Medical Imaging and Graphics},
  html={https://www.sciencedirect.com/science/article/abs/pii/S0895611121000732},
  year={2021},
  pdf={cmig_arafat_2021.pdf},
  abstract={Fuhrman cancer grading and tumor-node-metastasis (TNM) cancer staging systems are typically used by clinicians in the treatment planning of renal cell carcinoma (RCC), a common cancer in men and women worldwide. Pathologists typically use percutaneous renal biopsy for RCC grading, while staging is performed by volumetric medical image analysis before renal surgery. Recent studies suggest that clinicians can effectively perform these classification tasks non-invasively by analysing image texture features of RCC from computed tomography (CT) data. However, image feature identification for RCC grading and staging often relies on laborious manual processes, which is error prone and time-intensive. To address this challenge, this paper proposes a learnable image histogram in the deep neural network framework that can learn task-specific image histograms with variable bin centers and widths. The proposed approach enables learning statistical context features from raw medical data, which cannot be performed by a conventional convolutional neural network (CNN). The linear basis function of our learnable image histogram is piece-wise differentiable, enabling back-propagating errors to update the variable bin centers and widths during training. This novel approach can segregate the CT textures of an RCC in different intensity spectra, which enables effcient Fuhrman low (I/II) and high (III/IV) grading as well as RCC low (I/II) and high (III/IV) staging. The proposed method is validated on a clinical CT dataset of 159 patients from The Cancer Imaging Archive (TCIA) database, and it demonstrates 80% and 83% accuracy in RCC grading and staging, respectively.},
  code={https://github.com/marafathussain/ImHistNet},
  publisher={Elsevier}
}

@article{hussain2021cascaded,
  abbr={IEEE TMI},
  selected={true},
  bibtex_show={true},
  title={Cascaded Localization Regression Neural Nets for Kidney Localization and Segmentation-free Volume Estimation},
  author={Hussain, Mohammad Arafat and Hamarneh, Ghassan and Garbi, Rafeef},
  journal={IEEE Transactions on Medical Imaging},
  year={2021},
  html={https://ieeexplore.ieee.org/abstract/document/9358223?casa_token=rxZNi4GaP-YAAAAA:vlaAvOf6J1pKBT9goM4k0cCgPyJQ9NgOg_SSzt4iAFwHINOSelv-LsPXU44-XYmkME_wsI8},
  pdf={tmi2021.pdf},
  abstract={Kidney volume is an essential biomarker for a number of kidney disease diagnoses, for example, chronic kidney disease. Existing total kidney volume estimation methods often rely on an intermediate kidney segmentation step. On the other hand, automatic kidney localization in volumetric medical images is a critical step that often precedes subsequent data processing and analysis. Most current approaches perform kidney localization via an intermediate classification or regression step. This paper proposes an integrated deep learning approach for (i) kidney localization in computed tomography scans and (ii) segmentation-free renal volume estimation. Our localization method uses a selection-convolutional neural network that approximates the kidney inferior-superior span along the axial direction. Cross-sectional (2D) slices from the estimated span are subsequently used in a combined sagittal-axial Mask-RCNN that detects the organ bounding boxes on the axial and sagittal slices, the combination of which produces a final 3D organ bounding box. Furthermore, we use a fully convolutional network to estimate the kidney volume that skips the segmentation procedure. We also present a mathematical expression to approximate the ‘volume error’ metric from the ‘Sørensen–Dice coefficient.’ We accessed 100 patients’ CT scans from the Vancouver General Hospital records and obtained 210 patients’ CT scans from the 2019 Kidney Tumor Segmentation Challenge database to validate our method. Our method produces a kidney boundary wall localization error of ~2.4mm and a mean volume estimation error of ~5%.},
  publisher={IEEE}
}

@inproceedings{hussain2019imhistnet,
  abbr={MICCAI},
  bibtex_show={true},
  title={ImHistNet: Learnable image histogram based DNN with application to noninvasive determination of carcinoma grades in CT scans},
  author={Hussain, Mohammad Arafat and Hamarneh, Ghassan and Garbi, Rafeef},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={130--138},
  year={2019},
  selected={false},
  html={https://link.springer.com/chapter/10.1007/978-3-030-32226-7_15},
  pdf={mahmiccai19.pdf},
  abstract={Renal cell carcinoma (RCC) is the seventh most common cancer worldwide, accounting for an estimated 140,000 global deaths annually. Clear cell RCC (ccRCC) is the major subtype of RCC and its biological aggressiveness affects prognosis and treatment planning. An important ccRCC prognostic predictor is its ‘grade’ for which the 4-tiered Fuhrman grading system is used. Although the Fuhrman grade can be identified by percutaneous renal biopsy, recent studies suggested that such grades may be non-invasively identified by studying image texture features of the ccRCC from computed tomography (CT) data. Such image feature based identification currently mostly relies on laborious manual processes based on visual inspection of 2D image slices that are time-consuming and subjective. In this paper, we propose a learnable image histogram based deep neural network approach that can perform the Fuhrman low (I/II) and high (III/IV) grade classification for ccRCC in CT scans. Validated on a clinical CT dataset of 159 patients from the TCIA database, our method classified ccRCC low and high grades with 80% accuracy and 85% AUC.},
  code={https://github.com/marafathussain/ImHistNet},
  organization={Springer, Cham}
}

@inproceedings{hussain2019renal,
  abbr={MICCAI-MLMI},
  bibtex_show={true},
  title={Renal Cell Carcinoma Staging with Learnable Image Histogram-Based Deep Neural Network},
  author={Hussain, Mohammad Arafat and Hamarneh, Ghassan and Garbi, Rafeef},
  booktitle={International Workshop on Machine Learning in Medical Imaging},
  pages={533--540},
  year={2019},
  selected={false},
  html={https://link.springer.com/chapter/10.1007/978-3-030-32692-0_61},
  pdf={mahmlmi19.pdf},
  abstract={Renal cell carcinoma (RCC) is the seventh most common cancer worldwide, accounting for an estimated 140,000 global deaths annually. An important RCC prognostic predictor is its ‘stage’ for which the tumor-node-metastasis (TNM) staging system is used. Although TNM staging is performed by radiologists via pre-surgery volumetric medical image analysis, a recent study suggested that such staging may be performed by studying the image features of the RCC from computed tomography (CT) data. Currently TNM staging mostly relies on laborious manual processes based on visual inspection of 2D CT image slices that are time-consuming and subjective; a recent study reported about   ∼ 25% misclassification in their patient pools. Recently, we proposed a learnable image histogram based deep neural network approach (ImHistNet) for RCC grading, which is capable of learning textural features directly from the CT images. In this paper, using a similar architecture, we perform the stage low (I/II) and high (III/IV) classification for RCC in CT scans. Validated on a clinical CT dataset of 159 patients from the TCIA database, our method classified RCC low and high stages with about 83% accuracy.},
  code={https://github.com/marafathussain/ImHistNet},
  organization={Springer, Cham}
}

@inproceedings{hussain2018noninvasive,
  abbr={MICCAI}, 
  bibtex_show={true},
  title={Noninvasive determination of gene mutations in clear cell renal cell carcinoma using multiple instance decisions aggregated CNN},
  author={Hussain, Mohammad Arafat and Hamarneh, Ghassan and Garbi, Rafeef},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={657--665},
  year={2018},
  selected={false},
  html={https://link.springer.com/chapter/10.1007/978-3-030-00934-2_73},
  pdf={Arafat_MICCAI18.pdf},
  abstract={Kidney clear cell renal cell carcinoma (ccRCC) is the major sub-type of RCC, constituting one the most common cancers worldwide accounting for a steadily increasing mortality rate with 350,000 new cases recorded in 2012. Understanding the underlying genetic mutations in ccRCC provides crucial information enabling malignancy staging and patient survival estimation thus plays a vital role in accurate ccRCC diagnosis, prognosis, treatment planning, and response assessment. Although the underlying gene mutations can be identified by whole genome sequencing of the ccRCC following invasive nephrectomy or kidney biopsy procedures, recent studies have suggested that such mutations may be noninvasively identified by studying image features of the ccRCC from Computed Tomography (CT) data. Such image feature identification currently relies on laborious manual processes based on visual inspection of 2D image slices that are time-consuming and subjective. In this paper, we propose a convolutional neural network approach for automatic detection of underlying ccRCC gene mutations from 3D CT volumes. We aggregate the mutation-presence/absence decisions for all the ccRCC slices in a kidney into a robust singular decision that determines whether the interrogated kidney bears a specific mutation or not. When validated on clinical CT datasets of 267 patients from the TCIA database, our method detected gene mutations with 94% accuracy.},
  organization={Springer, Cham}
}

@inproceedings{hussain2017segmentation,
  abbr={MICCAI},
  bibtex_show={true},
  title={Segmentation-free kidney localization and volume estimation using aggregated orthogonal decision CNNs},
  author={Hussain, Mohammad Arafat and Amir-Khalili, Alborz and Hamarneh, Ghassan and Abugharbieh, Rafeef},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={612--620},
  year={2017},
  selected={false},
  html={https://link.springer.com/chapter/10.1007/978-3-319-66179-7_70},
  pdf={Arafat_MICCAI17.pdf},
  abstract={Kidney volume is an important bio-marker in the clinical diagnosis of various renal diseases. For example, it plays an essential role in follow-up evaluation of kidney transplants. Most existing methods for volume estimation rely on kidney segmentation as a prerequisite step, which has various limitations such as initialization-sensitivity and computationally-expensive optimization. In this paper, we propose a hybrid localization-volume estimation deep learning approach capable of (i) localizing kidneys in abdominal CT images, and (ii) estimating renal volume without requiring segmentation. Our approach involves multiple levels of self-learning of image representation using convolutional neural layers, which we show better capture the rich and complex variability in kidney data, demonstrably outperforming hand-crafted feature representations. We validate our method on clinical data of 100 patients with a total of 200 kidney samples (left and right). Our results demonstrate a 55% increase in kidney boundary localization accuracy, and a 30% increase in volume estimation accuracy compared to recent state-of-the-art methods deploying regression-forest-based learning for the same tasks.},
  organization={Springer, Cham}
}

@inproceedings{hussain2017collage,
  abbr={MICCAI-MLMI},
  bibtex_show={true},
  title={Collage CNN for renal cell carcinoma detection from CT},
  author={Hussain, Mohammad Arafat and Amir-Khalili, Alborz and Hamarneh, Ghassan and Abugharbieh, Rafeef},
  booktitle={International Workshop on Machine Learning in Medical Imaging},
  pages={229--237},
  year={2017},
  selected={false},
  html={https://link.springer.com/chapter/10.1007/978-3-319-67389-9_27},
  pdf={Arafat_MLMI17.pdf},
  abstract={Renal cell carcinoma (RCC) is a common malignancy that accounts for a steadily increasing mortality rate worldwide. Widespread use of abdominal imaging in recent years, mainly CT and MRI, has significantly increased the detection rates of such cancers. However, detection still relies on a laborious manual process based on visual inspection of 2D image slices. In this paper, we propose an image collage based deep convolutional neural network (CNN) approach for automatic detection of pathological kidneys containing RCC. Our collage approach overcomes the absence of slice-wise training labels, enables slice-reshuffling based data augmentation, and offers favourable training time and performance compared to 3D CNNs. When validated on clinical CT datasets of 160 patients from the TCIA database, our method classified RCC cases vs. normal kidneys with 98% accuracy.},
  organization={Springer, Cham}
}


@inproceedings{hussain2016segmentation,
  abbr={MICCAI-MLMI},
  bibtex_show={true},
  title={Segmentation-free estimation of kidney volumes in CT with dual regression forests},
  author={Hussain, Mohammad Arafat and Hamarneh, Ghassan and O’Connell, Timothy W and Mohammed, Mohammed F and Abugharbieh, Rafeef},
  booktitle={International Workshop on Machine Learning in Medical Imaging},
  pages={156--163},
  year={2016},
  selected={false},
  html={https://link.springer.com/chapter/10.1007/978-3-319-47157-0_19},
  pdf={MLMI2016.pdf},
  abstract={Accurate estimation of kidney volume is essential for clinical diagnoses and therapeutic decisions related to renal diseases. Existing kidney volume estimation methods rely on an intermediate segmentation step that is subject to various limitations. In this work, we propose a segmentation-free, supervised learning approach that addresses the challenges of accurate kidney volume estimation caused by extensive variations in kidney shape, size and orientation across subjects. We develop dual regression forests to simultaneously predict the kidney area per image slice, and kidney span per image volume. We validate our method on a dataset of 45 subjects with a total of 90 kidney samples. We obtained a volume estimation accuracy higher than existing segmentation-free (by 72 %) and segmentation-based methods (by 82 %). Compared to a single regression model, the dual regression reduced the false positive area-estimates and improved volume estimation accuracy by 41 %. We also found a mean deviation of under 10 % between our estimated kidney volumes and those obtained manually by expert radiologists.},
  organization={Springer, Cham}
}

@inproceedings{kabir2010non,
  abbr={UKSim},
  bibtex_show={true},
  title={Non-linear down-sampling and signal reconstruction, without folding},
  author={Kabir, Hussain Mohammed Dipu and Alam, Syed Bahauddin and Azam, Md Isme and Hussain, Mohammad Arafat and Sazzad, ABM Rafi and Sakib, Md Nazmus and Matin, Md Abdul},
  booktitle={2010 Fourth UKSim European Symposium on Computer Modeling and Simulation},
  pages={142--146},
  year={2010},
  html={https://ieeexplore.ieee.org/abstract/document/5703672?casa_token=88mmjYne1iMAAAAA:9yQ6oJc_GOmZWNwEJcjLgM4zjCOe6eXiflpaxh3KwwamTd1v804e8-ETEK5IzAWFxzUEGsc},
  pdf={mah2010.pdf},
  abstract={This paper presents a theory of 1.5 factor nonlinear down-sampling, reconstruction and noise elimination. For linear down sampling of two or three factor, one sample is taken and next one or two samples are not taken/discarded. Here in non-linear down sampling two or three samples are taken and the next one is not taken. The purpose of this nonlinear down sampling is to send less data samples in voice communication. Though one sample is discarded after taking two samples value of this sample can be reconstructed from values of other samples. Here, two samples are at original sampling period, T s interval and next two samples are at 2T s interval. High-frequency sharp changes were extracted when sampled at T s interval. From received signal, discarded sample can be reconstructed from nearby four samples (Previous two and next two). When original signal contains higher frequency some error signal is introduced, after reconstruction. This error signal depends on original signal. Error signal is eliminated using original signal. Down-sampling is performed after sampling and signal reconstruction is performed just before hearing the sound.},
  organization={IEEE}
}

@article{hussain2014lesion,
  abbr={Ultrasonics},
  bibtex_show={true},
  title={Lesion edge preserved direct average strain estimation for ultrasound elasticity imaging},
  author={Hussain, Mohammad Arafat and Alam, Farzana and Rupa, Sharmin Akhtar and Awwal, Rayhana and Lee, Soo Yeol and Hasan, Md Kamrul},
  journal={Ultrasonics},
  volume={54},
  number={1},
  pages={137--146},
  year={2014},
  html={https://www.sciencedirect.com/science/article/pii/S0041624X13001686?casa_token=BkTjesAnkx8AAAAA:o0nLzpt357pVNIzqqgZyjv9HcAVKDrWhjjYGXTz6DnkTeUrTA6JfvdNg3NqkNgNvhC-0Nm9u},
  pdf={mah2014a.pdf},
  abstract={Elasticity imaging techniques with built-in or regularization-based smoothing feature for ensuring strain continuity are not intelligent enough to prevent distortion or lesion edge blurring while smoothing. This paper proposes a novel approach with built-in lesion edge preservation technique for high quality direct average strain imaging. An edge detection scheme, typically used in diffusion filtering is modified here for lesion edge detection. Based on the extracted edge information, lesion edges are preserved by modifying the strain determining cost function in the direct-average-strain-estimation (DASE) method. The proposed algorithm demonstrates approximately 3.42–4.25 dB improvement in terms of edge-mean-square-error (EMSE) than the other reported regularized or average strain estimation techniques in finite-element-modeling (FEM) simulation with almost no sacrifice in elastographic-signal-to-noise-ratio (SNRe) and elastographic-contrast-to-noise-ratio (CNRe) metrics. The efficacy of the proposed algorithm is also tested for the experimental phantom data and in vivo breast data. The results reveal that the proposed method can generate a high quality strain image delineating the lesion edge more clearly than the other reported strain estimation techniques that have been designed to ensure strain continuity. The computational cost, however, is little higher for the proposed method than the simpler DASE and considerably higher than that of the 2D analytic minimization (AM2D) method.},
  publisher={Elsevier}
}

@article{hussain2012direct,
  abbr={IEEE TUFFC},
  bibtex_show={true},
  title={Direct and gradient-based average strain estimation by using weighted nearest neighbor cross-correlation peaks},
  author={Hussain, Mohammad Arafat and Anas, Emran Mohammad Abu and Alam, S Kaisar and Lee, Soo Yeol and Hasan, Md Kamrul},
  journal={IEEE transactions on ultrasonics, ferroelectrics, and frequency control},
  volume={59},
  number={8},
  pages={1713--1728},
  year={2012},
  html={https://ieeexplore.ieee.org/abstract/document/6264135?casa_token=PIy45Ng4P0IAAAAA:oJcEziPV396ApM43mXRcCpUXmXhcqplWD-qOn4xAwO0OR3KPAr7V45m_YOU3z-AzQ82qyhg},
  pdf={mah2012a.pdf},
  abstract={In this paper, two novel approaches, gradientbased and direct strain estimation techniques, are proposed for high-quality average strain imaging incorporating a cost function maximization. Stiffness typically is a continuous function. Consequently, stiffness of proximal tissues is very close to that of the tissue corresponding to a given data window. Hence, a cost function is defined from exponentially weighted neighboring pre- and post-compression RF echo normalized cross-correlation peaks in the lateral (for displacement estimation) or in both the axial and the lateral (for direct strain estimation) directions. This enforces a controlled continuity in displacement/strain and average displacement/strain is calculated from the corresponding maximized cost function. Axial stress causes lateral shift in the tissue. Therefore, a 1-D post-compression echo segment is selected by incorporating Poisson's ratio. Two stretching factors are considered simultaneously in gradient-based strain estimation that allow imaging the lesions properly. The proposed time-domain gradient-based and direct-strain-estimation-based algorithms demonstrate significantly better performance in terms of elastographic signal-to-noise ratio (SNRe), elastographic contrast-to-noise ratio (CNRe), peak signal-to-noise ratio (PSNR), and mean structural similarity (MSSIM) than the other reported time-domain gradientbased and direct-strain-estimation techniques in finite element modeling (FEM) simulation and phantom experiments. For example, in FEM simulation, it has been found that the proposed direct strain estimation method can improve up to approximately 2.49 to 8.71, 2.2 to 6.63, 1.5 to 5, and 1.59 to 2.45 dB in the SNRe, CNRe, PSNR, and MSSIM compared with the traditional direct strain estimation method, respectively, and the proposed gradient-based algorithm demonstrates 2.99 to 16.26, 18.74 to 23.88, 3 to 9.5, and 0.6 to 5.36 dB improvement in the SNRe, CNRe, PSNR, and MSSIM, respectively, compared with a recently reported time-domain gradient-based technique. The range of improvement as noted above is for low to high applied strains. In addition, the comparative results using the in vivo breast data (including malignant or benign masses) also show that the lesion size is better defined by the proposed gradient-based average strain estimation technique.},
  publisher={IEEE}
}

@article{hasan2013using,
  abbr={IEEE TUFFC},
  bibtex_show={true},
  title={Using nearest neighbors for accurate estimation of ultrasonic attenuation in the spectral domain},
  author={Hasan, Md Kamrul and Hussain, Mohammad Arafat and Ara, Sharmin R and Lee, Soo Yeol and Alam, S Kaisar},
  journal={IEEE transactions on ultrasonics, ferroelectrics, and frequency control},
  volume={60},
  number={6},
  pages={1098--1114},
  year={2013},
  html={https://ieeexplore.ieee.org/abstract/document/6521059?casa_token=2s5boH1hizUAAAAA:eI8qGb0LDefeIogW6kTDUZ0fV26Yp8l9Z9gOL-G4hJ8VrkrlDKwO4SfH1Fn1vA69zdiooG4},
  pdf={mah2013a.pdf},
  abstract={Attenuation is a key diagnostic parameter of tissue pathology change and thus may play a vital role in the quantitative discrimination of malignant and benign tumors in soft tissue. In this paper, two novel techniques are proposed for estimating the average ultrasonic attenuation in soft tissue using the spectral domain weighted nearest neighbor method. Because the attenuation coefficient of soft tissues can be considered to be a continuous function in a small neighborhood, we directly estimate an average value of it from the slope of the regression line fitted to the 1) modified average midband fit value and 2) the average center frequency shift along the depth. To calculate the average midband fit value, an average regression line computed from the exponentially weighted short-time Fourier transform (STFT) of the neighboring 1-D signal blocks, in the axial and lateral directions, is fitted over the usable bandwidth of the normalized power spectrum. The average center frequency downshift is computed from the maximization of a cost function defined from the normalized spectral cross-correlation (NSCC) of exponentially weighted nearest neighbors in both directions. Different from the large spatial signal-block-based spectral stability approach, a costfunction- based approach incorporating NSCC functions of neighboring 1-D signal blocks is introduced. This paves the way for using comparatively smaller spatial area along the lateral direction, a necessity for producing more realistic attenuation estimates for heterogeneous tissue. For accurate estimation of the attenuation coefficient, we also adopt a reference-phantombased diffraction-correction technique for both methods. The proposed attenuation estimation algorithm demonstrates better performance than other reported techniques in the tissue-mimicking phantom and the in vivo breast data analysis.},
  publisher={IEEE}
}

@article{hussain2012robust,
  abbr={Ultras. Imag.},
  bibtex_show={true},
  title={Robust strain-estimation algorithm using combined radiofrequency and envelope cross-correlation with diffusion filtering},
  author={Hussain, Mohammad Arafat and Alam, S Kaisar and Lee, Soo Yeol and Hasan, Md Kamrul},
  journal={Ultrasonic imaging},
  volume={34},
  number={2},
  pages={93--109},
  year={2012},
  html={https://journals.sagepub.com/doi/abs/10.1177/016173461203400203?casa_token=BsoXF5galF8AAAAA:a6IOEWbjSXOOFT4xm6HjaWpQp411uUccdJsJLRy9pWZp7LPiJBpH1kxWMXYTztQTIroEIBM4rE0},
  pdf={mah2012b.pdf},
  abstract={In ultrasound elastography, the strain in compressed tissue due to external deformation is estimated and is smaller in harder than softer tissue. With increased stress, the nonaxial motions of tissue elements increase and result in noisier strain images. At high strain, the envelope of the rf signal exhibits robustness to signal decorrelation. However, the precision of strain estimates using envelope signals is much worse compared to that using the rf signals. In this paper, we propose a novel approach for robust strain estimation by combining weighted rf cross-correlation and envelope cross-correlation functions. An applied strain-dependent piecewise-linear-weight is used for this purpose. In addition, we introduce nonlinear diffusion filtering to further enhance the resulting strain image. The results of our algorithm are demonstrated for up to 10% applied strain using a finite-element modelling (FEM) simulation phantom. It reveals that the elastographic signal-to-noise ratio (SNRe) and the elastographic contrast-to-noise ratio (CNRe) of the strain images can be improved more significantly than with other algorithms used in this paper. In addition, comparative results in terms of the mean structural similarity (MSSIM) using in vivo breast data show that the strain image quality can be improved noticeably by the proposed method than with the techniques employed in this work.},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@inproceedings{hussain2014robust,
  abbr={MICCAI},
  bibtex_show={true},
  title={Robust bone detection in ultrasound using combined strain imaging and envelope signal power detection},
  author={Hussain, Mohammad Arafat and Hodgson, Antony and Abugharbieh, Rafeef},
  booktitle={International conference on medical image computing and computer-assisted intervention},
  pages={356--363},
  year={2014},
  html={https://link.springer.com/chapter/10.1007/978-3-319-10404-1_45},
  pdf={MICCAI2014.pdf},
  abstract={Bone localization in ultrasound (US) remains challenging despite encouraging advances. Current methods, e.g. local image phase-based feature analysis, showed promising results but remain reliant on delicate parameter selection processes and prone to errors at confounding soft tissue interfaces of similar appearance to bone interfaces. We propose a different approach combining US strain imaging and envelope power detection at each radio-frequency (RF) sample. After initial estimation of strain and envelope power maps, we modify their dynamic ranges into a modified strain map (MSM) and a modified envelope map (MEM) that we subsequently fuse into a single combined map that we show corresponds robustly to actual bone boundaries. Our quantitative results demonstrate a marked reduction in false positive responses at soft tissue interfaces and an increase in bone delineation accuracy. Comparisons to the state-of-the-art on a finite-element-modelling (FEM) phantom and fiducial-based experimental phantom show an average improvement in mean absolute error (MAE) between actual and estimated bone boundaries of 32% and 14%, respectively. We also demonstrate an average reduction in false bone responses of 87% and 56%, respectively. Finally, we qualitatively validate on clinical in vivo data of the human radius and ulna bones, and demonstrate similar improvements to those observed on phantoms.},
  organization={Springer, Cham}
}

@inproceedings{hussain2015compressively,
  abbr={ICEEE},
  bibtex_show={true},
  title={Compressively sensed ultrasound radio-frequency data reconstruction using the combined curvelets and wave atoms basis},
  author={Hussain, Mohammad Arafat and Shourov, Riad Mashrub},
  booktitle={2015 International Conference on Electrical \& Electronic Engineering (ICEEE)},
  pages={209--212},
  year={2015},
  html={https://ieeexplore.ieee.org/abstract/document/7428257?casa_token=XICEk4II6TIAAAAA:g1EyVRJBif0dyvwfNNe9xHFZZvjfLYcwee5A-FKCcQvPHnkxzFUwhTN5IcmZzRowekltrJs},
  pdf={mah2015a.pdf},
  abstract={In this paper, we propose a novel data reconstruction method for the compressively sensed ultrasound radio-frequency (RF) data using the combined curvelets- and wave atoms- (CCW) based orthonormal basis. Typically, the curvelets-based reconstruction better preserves the image features while the wave atoms-based reconstruction better preserves the oscillatory patterns of the typical ultrasound RF signals. We exploit the advantages from both the sparsifying bases via concatenating them where the RF reconstruction is done from the larger coefficients of the combined basis. We show that the CCW-based reconstruction method better recovers the RF oscillatory patterns as well as preserves the image features better than those of the curvelets- and wave atoms-based reconstruction methods alone. We find improvement with respect to the current methods of approximately 58% and 64% in terms of the normalized mean square error for the reconstructed synthetic phantom and in vivo RF data, respectively. We also show visual performance improvement in the B-mode images of approximately 33% and 44% in terms of the mean structural similarity for the synthetic phantom and in vivo data, respectively.},
  organization={IEEE}
}

@inproceedings{hussain2015towards,
  abbr={ICCIT},
  bibtex_show={true},
  title={Towards real-time 3D geometric nonlinear diffusion filter and its application to CT and MR imaging},
  author={Hussain, Mohammad Arafat and Shourov, Riad Mashrub and Khan, Shamima Nasrin},
  booktitle={2015 18th International Conference on Computer and Information Technology (ICCIT)},
  pages={462--467},
  year={2015},
  html={https://ieeexplore.ieee.org/abstract/document/7488115?casa_token=It1Pi7OtLEsAAAAA:F9bEARHP7syb_INZH1bJxrC_2RkyV4wyK1XJfNj4EvzUqFd9oVBAr8-9Nir8y-ad3ZusOa8},
  pdf={mah2015b.pdf},
  abstract={We propose two near real-time nonlinear anisotropic diffusion filtering (NADF) methods for the 2D and 3D X-ray computed tomography (CT) and magnetic resonance (MR) image denoising. Typically, NADFs are preferred for the medical image denoising due to its edge preserving feature though they are computationally expensive. Recently, a computation-time efficient 2D NADF has been proposed which uses local pixel intensity-based geometric parameters for diffusion. But it has limitations resulting from (i) its assumption that the neighboring pixels are non-noisy while deciding on an interrogated pixel being noisy or not, and (ii) its confinement of working only on a 2D image. Motivated from this, we propose an improved 2D NADF method that uses additional neighboring pixels in an effective way to lower the noise impact on the estimated geometric parameters. We also extend our 2D method into 3D that considers all the three directions for information diffusion. The performance of the proposed methods is evaluated using a 3D synthetic phantom, and in vivo CT and MR data which demonstrates an average signal-to-noise-ratio-gain improvement of approximately 58% in 2D and 96% in 3D phantom data, and approximately 79% in 2D and 127% in 3D in vivo data, compared to the state-of-the-art method.},
  organization={IEEE}
}

@inproceedings{hussain2015automatic,
  abbr={CAOS},
  bibtex_show={true},
  title={Automatic Bone Segmentation in Ultrasound using Combined Ultrasound Strain Imaging and Envelope Signal Power},
  author={Hussain, Mohammad Arafat and Guy, Pierre and Hodgson, Antony J and Abugharbieh, Rafeef},
  booktitle={2015 International Meeting on Computer Assisted Orthopaedic Surgery (CAOS)},
  year={2015},
  pdf={CAOS2015.pdf},
  organization={CAOS}
}


@article{hussain2017strain,
  abbr={UMB},
  bibtex_show={true},
  title={Strain-initialized robust bone surface detection in 3-D ultrasound},
  author={Hussain, Mohammad Arafat and Hodgson, Antony J and Abugharbieh, Rafeef},
  journal={Ultrasound in medicine \& biology},
  volume={43},
  number={3},
  pages={648--661},
  year={2017},
  html={https://www.sciencedirect.com/science/article/pii/S0301562916303696?casa_token=krY2KlUluY8AAAAA:5y7hfrUvrHjJkcsVWHnUtw5g3Wa3KWuLRwL3oSu8Ggn6YjiCxEd166yYSrWmEingXL1H09FN},
  pdf={Arafat_UMB17.pdf},
  abstract={Three-dimensional ultrasound has been increasingly considered as a safe radiation-free alternative to radiation-based fluoroscopic imaging for surgical guidance during computer-assisted orthopedic interventions, but because ultrasound images contain significant artifacts, it is challenging to automatically extract bone surfaces from these images. We propose an effective way to extract 3-D bone surfaces using a surface growing approach that is seeded from 2-D bone contours. The initial 2-D bone contours are estimated from a combination of ultrasound strain images and envelope power images. Novel features of the proposed method include: (i) improvement of a previously reported 2-D strain imaging-based bone segmentation method by incorporation of a depth-dependent cumulative power of the envelope into the elastographic data; (ii) incorporation of an echo decorrelation measure-based weight to fuse the strain and envelope maps; (iii) use of local statistics of the bone surface candidate points to detect the presence of any bone discontinuity; and (iv) an extension of our 2-D bone contour into a 3-D bone surface by use of an effective surface growing approach. Our new method produced average improvements in the mean absolute error of 18% and 23%, respectively, on 2-D and 3-D experimental phantom data, compared with those of two state-of-the-art bone segmentation methods. Validation on 2-D and 3-D clinical in vivo data also reveals, respectively, an average improvement in the mean absolute fitting error of 55% and an 18-fold improvement in the computation time.},
  publisher={Elsevier}
}

@phdthesis{hussain2020volumetric,
  abbr={PhD Thesis},
  bibtex_show={true},
  title={Volumetric image-based supervised learning approaches for kidney cancer detection and analysis},
  author={Hussain, Mohammad Arafat},
  year={2020},
  selected={false},
  html={https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0389786},
  pdf={https://open.library.ubc.ca/media/download/pdf/24/1.0389786/4},
  school={University of British Columbia}
}

@phdthesis{hussain2015robust,
  abbr={MASc Thesis},
  title={Robust Bone Detection in Ultrasound Using Combined Strain Imaging and Envelope Signal Power Detection},
  author={Hussain, Mohammad Arafat},
  year={2015},
  selected={false},
  html={https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0166292},
  pdf={https://open.library.ubc.ca/media/download/pdf/24/1.0166292/3},
  school={University of British Columbia}
}

@phdthesis{hussain2013average,
  abbr={MSc Thesis},
  title={Average Strain Estimation for Ultrasound Elastography Using Exponentially Weighted Nearest Neighbors},
  author={Hussain, Mohammad Arafat},
  year={2013},
  selected={false},
  html={http://lib.buet.ac.bd:8080/xmlui/handle/123456789/3451},
  pdf={https://app.box.com/s/xhqnrd7zzz6tkmauvav2sjtywwu2gbaz},
  school={Bangladesh University of Engineering and Technology}
}

@phdthesis{hussain2011ultrasound,
  abbr={BSc Thesis},
  title={Ultrasound Strain Imaging in Wavelet Domain},
  author={Islam, Md Tauhidul* and Hussain, Mohammad Arafat*},
  year={2011},
  selected={false},
  pdf={https://app.box.com/s/5ia82d9nu3wbscz9nmfyeys1rifx7bu3},
  school={Bangladesh University of Engineering and Technology}
}

@inproceedings{hussain2012improved,
  abbr={ABS-AIUM},
  title={Improved Elasticity Imaging by Maximizing the Weighted Peaks of the Nearest Neighbor Cross-correlation Function},
  author={Hussain, Mohammad Arafat and Anas, Emran Mohammad Abu and Alam, S Kaisar and Lee, Soo Yeol and Hasan, Md Kamrul},
  booktitle={2012 American Institution of Ultrasound in Medicine (AIUM) Annual Convention and Preconvention Program},
  year={2012},
  slides={mah2012c.pdf},
  organization={AIUM}
}

@inproceedings{hussain2012robust,
  abbr={ABS-UITS},
  title={A Robust Strain Estimation Algorithm Using Combined Radio-frequency and Envelope Cross-correlation},
  author={Hussain, Mohammad Arafat and Alam, S Kaisar and Lee, Soo Yeol and Hasan, Md Kamrul},
  booktitle={Ultrasonic Imaging and Tissue Characterization Symposium},
  year={2012},
  slides={mah2012d.pdf},
  organization={UITC}
}
