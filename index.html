<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Mohammad Arafat Hussain, PhD</title> <meta name="author" content="Mohammad Arafat Hussain, PhD"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://marafathussain.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6D%6F%68%61%6D%6D%61%64.%68%75%73%73%61%69%6E@%63%68%69%6C%64%72%65%6E%73.%68%61%72%76%61%72%64.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-0545-5779" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=https://scholar.google.ca/citations?user=hFwvdQcAAAAJ&amp;hl=en" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/M.-Hussain/2067311" title="Semantic Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-semantic-scholar"></i></a> <a href="https://www.researchgate.net/profile/Mohammad-Arafat-Hussain/" title="ResearchGate" target="_blank" rel="noopener noreferrer"><i class="ai ai-researchgate"></i></a> <a href="https://github.com/marafathussain" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/hussainma" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://dblp.org/pid/148/7569.html" title="DBLP" target="_blank" rel="noopener noreferrer"><i class="ai ai-dblp"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Mohammad Arafat</span> Hussain, PhD </h1> <p class="desc">Research Fellow, Boston Children's Hospital, Harvard Medical School</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/arafat_new-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/arafat_new-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/arafat_new-1400.webp"></source> <img src="/assets/img/arafat_new.png" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="arafat_new.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p>Children's Hospital,</p> <p>Landmark Center,</p> <p>401 Park Dr, Boston,</p> <p>MA 02115, USA</p> </div> </div> <div class="clearfix"> <p>[<a href="https://connects.catalyst.harvard.edu/Profiles/display/Person/201410" target="_blank" rel="noopener noreferrer">Harvard Catalyst Profile</a>] [<a href="https://brain.harvard.edu/hbi_connectome/mohammad-arafat-hussain/" target="_blank" rel="noopener noreferrer">HBI Connectome</a>] [<a href="https://research.childrenshospital.org/arafat" target="_blank" rel="noopener noreferrer">Boston Children’s</a>]</p> <p>I am currently a Postdoctoral Research Fellow in the <a href="https://www.fnndsc.org/" target="_blank" rel="noopener noreferrer">Fetal-Neonatal Neuroimaging Developmental Science Center</a> at Harvard Medical School, Boston, Massachusetts. My research interests lie in machine/deep learning and its application to medical image analysis.</p> <p>Previously, I worked as a Postdoctoral Research Associate in the <a href="https://www.medicalimageanalysis.com/" target="_blank" rel="noopener noreferrer">Medical Image Analysis Lab (MIAL)</a> at <a href="https://www.sfu.ca/computing.html" target="_blank" rel="noopener noreferrer">Simon Fraser University</a>, Burnaby, BC, Canada.</p> <p>I completed my Ph.D. in Biomedical Engineering at the <a href="https://bisicl.ece.ubc.ca/" target="_blank" rel="noopener noreferrer">University of British Columbia (UBC)</a>, Vancouver. In my Ph.D. project, I primarily focused on kidney cancer detection and analysis in CT using deep learning. I also completed my M.A.Sc. in Biomedical Engineering at UBC, Vancouver. My M.A.Sc. project focused on robust bone boundary localization in ultrasound to facilitate minimally invasive ultrasound-guided orthopedic surgery.</p> <p>Before joining UBC, I completed an M.Sc. and B.Sc. in Electrical and Electronic Engineering at <a href="https://www.buet.ac.bd/web/" target="_blank" rel="noopener noreferrer">Bangladesh University of Engineering &amp; Technology (BUET)</a>. During my M.Sc., I worked as a Research Engineer and developed novel ultrasound elastography techniques for breast cancer detection. I also worked as a Software Engineer in the <a href="https://research.samsung.com/srbd" target="_blank" rel="noopener noreferrer">Samsung R&amp;D Institute Bangladesh</a> after completing my B.Sc. degree.</p> </div> <div class="news"> <h2>news</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Nov 7, 2024</th> <td> Paper accepted in Frontiers in Neuroimaging [<a href="https://www.frontiersin.org/journals/neuroimaging/articles/10.3389/fnimg.2024.1455436/pdf" target="_blank" rel="noopener noreferrer">PDF</a>] <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Oct 30, 2024</th> <td> Paper accepted in Scientific Reports - Nature [<a href="https://rdcu.be/dZ9O7" target="_blank" rel="noopener noreferrer">PDF</a>] <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Sep 12, 2024</th> <td> Awarded a competitive research grant from the [<a href="https://benchtobassinet.com/?page_id=2531" target="_blank" rel="noopener noreferrer">PCGC and CDDRC Fellows Program</a>] <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Jul 16, 2024</th> <td> Paper accepted in MICCAI-PRIME 2024 [<a href="https://github.com/marafathussain/marafathussain.github.io/blob/source/assets/pdf/prime2024.pdf" target="_blank" rel="noopener noreferrer">Preprint</a>] </td> </tr> <tr> <th scope="row">May 13, 2024</th> <td> Paper accepted in Medical Engineering &amp; Physics [<a href="https://www.sciencedirect.com/science/article/pii/S1350453324000808" target="_blank" rel="noopener noreferrer">Link</a>] </td> </tr> </table> </div> </div> <div class="publications"> <h2>selected publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">F. Neuroim.</abbr></div> <div id="hussain2024inferring" class="col-sm-8"> <div class="title">Inferring Neurocognition Using Artificial Intelligence on Brain MRIs</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>Frontiers in Neuroimaging</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.frontiersin.org/journals/neuroimaging/articles/10.3389/fnimg.2024.1455436/full" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://www.frontiersin.org/journals/neuroimaging/articles/10.3389/fnimg.2024.1455436/pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.frontiersin.org/api/v3/articles/1455436/file/Image_1.pdf/1455436_image_1/1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Supp</a> </div> <div class="abstract hidden"> <p>Brain magnetic resonance imaging (MRI) offers a unique lens to study neuroanatomic support of human neurocognition and intelligence. A core mystery is the MRI explanation of individual differences in neurocognition and intelligence. The past four decades have seen great advancement in studying this century-long mystery, but the sample size and population-level studies limit the explanation at the individual level. The recent rise of big data and artificial intelligence offers novel opportunities. Yet, data sources, harmonization, study design, and interpretation need to be carefully considered. This review aims to summarize past work, discuss rising opportunities and challenges, and facilitate further investigations on machine intelligence inferring human intelligence.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hussain2024inferring</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3389/fnimg.2024.1455436}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Neuroimaging}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1455436}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Inferring Neurocognition Using Artificial Intelligence on Brain MRIs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Frontiers in Neuroimaging}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">PAS</abbr></div> <div id="ou2025combining" class="col-sm-8"> <div class="title"> Combining 47 clinical and neuroimaging variables to predict adverse 18-22-month outcomes for Hypoxic Ischemic Encephalopathy in Neonatal Research Network trials.</div> <div class="author"> <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a>, Ankush Kesri, Rina Bao, Chuan-Heng Hsiao, Rutvi Vyas, <em>Mohammad Arafat Hussain</em>, Scott McDonald, Jeanette Auman, Anna Foster, Erfan Darzi, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Matheus Soldatelli, Seetha Shankaran, Abbott Laptook, Michael Cotten, Ellen Grant' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In Pediatric Academic Societies 2025 Meeting</em> 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/pas_2025.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ou2025combining</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ Combining 47 clinical and neuroimaging variables to predict adverse 18-22-month outcomes for Hypoxic Ischemic Encephalopathy in Neonatal Research Network trials.}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ou, Yangming and Kesri, Ankush and Bao, Rina and Hsiao, Chuan-Heng and Vyas, Rutvi and Hussain, Mohammad Arafat and McDonald, Scott and Auman, Jeanette and Foster, Anna and Darzi, Erfan and Soldatelli, Matheus and Shankaran, Seetha and Laptook, Abbott and Cotten, Michael and Grant, Ellen}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Pediatric Academic Societies 2025 Meeting}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{PAS}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ASPNR</abbr></div> <div id="Kesri2024therole" class="col-sm-8"> <div class="title">The Role of Expert MRI Scores in Predicting Adverse 18-22-month Outcomes for Hypoxic Ischemic Encephalopathy in Neonatal Research Network Trials</div> <div class="author"> Ankush Kesri, Rina Bao, Chuan-Heng Hsiao, Rutvi Vyas, <em>Mohammad Arafat Hussain</em>, Scott McDonald, Jeanette Auman, Seetha Shankaran, Abbott Laptook, Michael Cotten, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Ellen Grant, Yangming Ou' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In 7th Annual Meeting of American Society of Pediatric Neuroradiology</em> 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ASPNR_abstract_2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Kesri2024therole</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Role of Expert MRI Scores in Predicting Adverse 18-22-month Outcomes for Hypoxic Ischemic Encephalopathy in Neonatal Research Network Trials}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kesri, Ankush and Bao, Rina and Hsiao, Chuan-Heng and Vyas, Rutvi and Hussain, Mohammad Arafat and McDonald, Scott and Auman, Jeanette and Shankaran, Seetha and Laptook, Abbott and Cotten, Michael and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{7th Annual Meeting of American Society of Pediatric Neuroradiology}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{ASPNR}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Scientific Reports</abbr></div> <div id="hussain2024deep" class="col-sm-8"> <div class="title">Deep Learning of Structural MRI Predicts Fluid, Crystallized, and General Intelligence</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, Danielle LaMay, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>Scientific Reports - Nature</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s41598-024-78157-0" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://rdcu.be/dZ9O7" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-024-78157-0/MediaObjects/41598_2024_78157_MOESM1_ESM.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Supp</a> <a href="https://github.com/i3-research/MRI-infer-neurocognition" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Can brain structure predict human intelligence? T1-weighted structural brain magnetic resonance images (sMRI) have been correlated with intelligence. Nevertheless, population-level association does not fully account for individual variability in intelligence. To address this, individual prediction studies emerge recently. However, they are mostly on predicting fluid intelligence (the ability to solve new problems). Studies are lacking to predict crystallized intelligence (the ability to accumulate knowledge) or general intelligence (fluid and crystallized intelligence combined). This study tests whether deep learning of sMRI can predict an individual subject’s verbal, comprehensive, and full-scale intelligence quotients (VIQ, PIQ, FSIQ), which reflect both fluid and crystallized intelligence. We performed a comprehensive set of 432 experiments, using different input images, six deep learning models, and two outcome settings, on 850 autistic and healthy subjects 6-64 years of age. Results show promise with statistical significance, and also open up questions inviting further future studies.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hussain2024deep</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41598-024-78157-0}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep Learning of Structural MRI Predicts Fluid, Crystallized, and General Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and LaMay, Danielle and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific Reports - Nature}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Nature}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">PRIME</abbr></div> <div id="hussain2024rct" class="col-sm-8"> <div class="title">RCT: Relational Connectivity Transformer for Enhanced Prediction of Absolute and Residual Intelligence</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>In 7th International Workshop of Predictive Intelligence in Medicine (PRIME)</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-74561-4_4" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/prime2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/marafathussain/RelationalConnectivityTransformer" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>This paper introduces the Relational Connectivity Transformer (RCT), a novel Graph-Transformer model designed for predicting absolute and residual full-scale intelligence quotient (FSIQ), performance IQ (PIQ), and verbal IQ (VIQ) scores from resting-state functional magnetic resonance imaging (rs-fMRI) data. Early prediction of neurocognitive impairments via IQ scores may allow for timely intervention. To this end, our RCT model leverages a relation-learning strategy from paired sample data via a novel graph-based transformer framework. Through a comprehensive comparison with state-of-the-art approaches in a 5-fold cross-validation setup, our model demonstrated superior performance. Statistical analysis confirmed the significant improvement (p &lt; 0.05) in FSIQ prediction, strengthening the efficacy of the proposed method. This work marks the first application of a Graph-Transformer in predicting IQ scores using rs-fMRI, introducing a novel learning strategy and contributing to the ongoing efforts to enhance the accuracy and reliability of human intelligence predictions based on functional brain connectivity.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">hussain2024rct</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{RCT: Relational Connectivity Transformer for Enhanced Prediction of Absolute and Residual Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{7th International Workshop of Predictive Intelligence in Medicine (PRIME)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer, Cham}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div> <div id="bao2024foundationaimodelmedical" class="col-sm-8"> <div class="title">Foundation AI Model for Medical Image Segmentation</div> <div class="author"> Rina Bao, Erfan Darzi, Sheng He, Chuan-Heng Hsiao, <em>Mohammad Arafat Hussain</em>, Jingpeng Li, Atle Bjornerud, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em></em> 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2411.02745" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2411.02745" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bao2024foundationaimodelmedical</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Foundation AI Model for Medical Image Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bao, Rina and Darzi, Erfan and He, Sheng and Hsiao, Chuan-Heng and Hussain, Mohammad Arafat and Li, Jingpeng and Bjornerud, Atle and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">MEP</abbr></div> <div id="marhamati2024patient" class="col-sm-8"> <div class="title">Patient’s Airway Monitoring during Cardiopulmonary Resuscitation using Deep Networks</div> <div class="author"> Mahmoud Marhamati, Behnam Dorri, Shima Imannezhad, <em>Mohammad Arafat Hussain</em>, Ali Asghar Neshat, Abulfazl Kakmishi, and Mohammad Momeny</div> <div class="periodical"> <em>Medical Engineering &amp; Physics</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S1350453324000808" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/mah2024a.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Cardiopulmonary resuscitation (CPR) is a crucial life-saving technique commonly administered to individuals experiencing cardiac arrest. Among the important aspects of CPR is ensuring the correct airway position of the patient, which is typically monitored by human tutors or supervisors. This study aims to utilize deep transfer learning for the detection of the patient’s correct and incorrect airway position during cardiopulmonary resuscitation. To address the challenge of identifying the airway position, we curated a dataset consisting of 198 recorded video sequences, each lasting 6-8 seconds, showcasing both correct and incorrect airway positions during mouth-to-mouth breathing and breathing with an Ambu Bag. We employed six cutting-edge deep networks, namely DarkNet19, EfficientNetB0, GoogleNet, MobileNet-v2, ResNet50, and NasnetMobile. These networks were initially pre-trained on computer vision data and subsequently fine-tuned using the CPR dataset. The validation of the fine-tuned networks in detecting the patient’s correct airway position during mouth-to-mouth breathing achieved impressive results, with the best sensitivity (98.8%), specificity (100%), and F-measure (97.2%). Similarly, the detection of the patient’s correct airway position during breathing with an Ambu Bag exhibited excellent performance, with the best sensitivity (100%), specificity (99.8%), and F-measure (99.7%).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">marhamati2024patient</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.medengphy.2024.104179}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Patient's Airway Monitoring during Cardiopulmonary Resuscitation using Deep Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Marhamati, Mahmoud and Dorri, Behnam and Imannezhad, Shima and Hussain, Mohammad Arafat and Neshat, Ali Asghar and Kakmishi, Abulfazl and Momeny, Mohammad}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Engineering \&amp; Physics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{104179}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">bioRxiv</abbr></div> <div id="hussain2023enhancing" class="col-sm-8"> <div class="title">Enhancing Neurocognitive Outcome Prediction in Congenital Heart Disease Patients: The Role of Brain Age Biomarkers and Beyond</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>bioRxiv</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.biorxiv.org/content/10.1101/2023.09.01.555976v1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/CHD_Neuro_2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This paper aimed to investigate the predictive power of combining demographic, socioeconomic, and genetic factors with a brain MRI-based quantified measure of accelerated brain aging (referred to as deltaAGE) for neurocognitive outcomes in adolescents and young adults with Congenital Heart Disease (CHD). Our hypothesis posited that including the brain age biomarker (deltaAGE) would enhance neurocognitive outcome predictions compared to models excluding it. We conducted comprehensive analyses, including leave-one-subject-out and leave-one-group-out cross-validation techniques. Our results demonstrated that the inclusion of deltaAGE consistently improved prediction performance when considering the Pearson correlation coefficient, a preferable metric for this study. Notably, the deltaAGE-augmented models consistently outperformed those without deltaAGE across all cross-validation setups, and these correlations were statistically significant (p-value &lt; 0.05). Therefore, our hypothesis that incorporating the brain-age biomarker alongside demographic, socioeconomic, and genetic factors enhances neurocognitive outcome predictions in adolescents and young adults with CHD is supported by the findings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hussain2023enhancing</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1101/2023.09.01.555976}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2023-02}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Enhancing Neurocognitive Outcome Prediction in Congenital Heart Disease Patients: The Role of Brain Age Biomarkers and Beyond}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{bioRxiv}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Cold Spring Harbor Laboratory}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Displays</abbr></div> <div id="MARHAMATI2023102371" class="col-sm-8"> <div class="title">LAIU-Net: A learning-to-augment incorporated robust U-Net for depressed humans’ tongue segmentation</div> <div class="author"> Mahmoud Marhamati, Ali Asghar Latifi Zadeh, Masoud Mojdehi Fard, <em>Mohammad Arafat Hussain</em>, Khalegh Jafarnezhad, Ahad Jafarnezhad, Mehdi Bakhtoor, and Mohammad Momeny</div> <div class="periodical"> <em>Displays</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0141938223000045" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/displays2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/mohamadmomeny/Learning-to-augment-strategy" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Computer-aided tongue diagnosis system requires segmentation of the tongue body. The frequent movement of the tongue due to its natural flexibility often causes shape variability in photographs across subjects, which makes segmenting the tongue challenging from non-tongue elements, such as the lips, teeth, and other objects in the background of the tongue. The flexibility of the tongue causes a further challenge in maintaining a similar shape and style when taking photos of many healthy subjects and patients. To address these challenges, we have built a tongue dataset, where the tongue of each subject has been scanned thrice with an interval of less than a second. We have collected 333 tongue images from 111 depressed humans, who have been diagnosed with depression by a psychiatrist. In addition, in this paper, we propose a learning-to-augment incorporated U-Net (LAIU-Net) for the segmentation of the depressed human tongue in photographic images. The best policies for data augmentation were automatically chosen with the proposed LAIU-Net. For this purpose, we corrupted photographic tongue images with the Gaussian, speckle, and Poisson noise. The proposed approach addresses the overfitting problem as well as increases the generalizability of a deep network. We have compared the performance of the proposed LAIU-Net with that of other state-of-the-art U-Net configurations. Our LAIU-Net approach achieved a mean boundary F1 score of 93.1%.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">MARHAMATI2023102371</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LAIU-Net: A learning-to-augment incorporated robust U-Net for depressed humans’ tongue segmentation}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Displays}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{102371}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0141-9382}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.displa.2023.102371}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Marhamati, Mahmoud and Zadeh, Ali Asghar Latifi and Fard, Masoud Mojdehi and Hussain, Mohammad Arafat and Jafarnezhad, Khalegh and Jafarnezhad, Ahad and Bakhtoor, Mehdi and Momeny, Mohammad}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Tongue segmentation, learning-to-augment strategy, data augmentation, deep learning, U-Net}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div> <div id="morshed2024ultrasound" class="col-sm-8"> <div class="title">Ultrasound-Based AI for COVID-19 Detection: A Comprehensive Review of Public and Private Lung Ultrasound Datasets and Studies [In review]</div> <div class="author"> Abrar Morshed, Abdulla Al Shihab, Md Abrar Jahin, Md Jaber Al Nahian, Md Murad Hossain Sarker, Md Sharjis Ibne Wadud, Other Authors, and <em>Mohammad Arafat Hussain</em> </div> <div class="periodical"> <em>arXiv</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2411.05029" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2411.05029" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The COVID-19 pandemic has affected millions of people globally, with respiratory organs being strongly affected in individuals with comorbidities. Medical imaging-based diagnosis and prognosis have become increasingly popular in clinical settings to detect COVID-19 lung infections. Among various medical imaging modalities, ultrasound stands out as low-cost, mobile, and radiation-safe imaging technology. In this comprehensive review, we focus on ultrasound-based AI studies for COVID-19 detection that use public or private lung ultrasound datasets. We surveyed articles that used publicly available lung ultrasound datasets for COVID-19 and reviewed publicly available datasets and organize ultrasound-based AI studies per dataset. We analyzed and tabulated studies in several dimensions, such as data preprocessing, AI models, cross-validation, and evaluation criteria. In total, we reviewed 42 articles, where 28 articles used public datasets, and the rest used private data. Our findings suggest that ultrasound-based AI studies for the detection of COVID-19 have great potential for clinical use, especially for children and pregnant women. Our review also provides a useful summary for future researchers and clinicians who may be interested in the field.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">morshed2024ultrasound</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.48550/arXiv.2411.05029}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Ultrasound-Based AI for COVID-19 Detection: A Comprehensive Review of Public and Private Lung Ultrasound Datasets and Studies [In review]}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morshed, Abrar and Al Shihab, Abdulla and Jahin, Md Abrar and Al Nahian, Md Jaber and Sarker, Md Murad Hossain and Wadud, Md Sharjis Ibne and Authors, Other and Hussain, Mohammad Arafat}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{arXiv}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Nature Conf.</abbr></div> <div id="hussain2022machine" class="col-sm-8"> <div class="title">Machine Intelligence to Predict Human Intelligence</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, Danielle LaMay, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>In AI, neuroscience and hardware: From neural to artificial systems and back again</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/mah_nat_2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/Nature_AI_Poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">hussain2022machine</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Machine Intelligence to Predict Human Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and LaMay, Danielle and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AI, neuroscience and hardware: From neural to artificial systems and back again}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Nature Conferences}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Mohammad Arafat Hussain, PhD. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>